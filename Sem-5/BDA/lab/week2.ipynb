{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba395912",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/07/31 08:11:56 WARN Utils: Your hostname, dbl-07, resolves to a loopback address: 127.0.1.1; using 172.16.58.102 instead (on interface eno1)\n",
      "25/07/31 08:11:56 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/07/31 08:11:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "sc=SparkContext('local','Pyspark RDD transformations')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd61212",
   "metadata": {},
   "source": [
    "pyspark.sql.type =>spark . It has StructType which helps in defining schema.\n",
    "it makes csv sing StructField => ((col.name,struct-type,nullable?))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01deb826",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c4f937f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb0ac89",
   "metadata": {},
   "source": [
    "### Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e11d3a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema= StructType([StructField(\"Index\",IntegerType(),True),\n",
    "                    StructField(\"Customer Id\",StringType(),True),\n",
    "                    StructField(\"First Name\",StringType(),True),\n",
    "                    StructField(\"Last Name\",StringType(),True),\n",
    "                    StructField(\"Company\",StringType(),True),\n",
    "                    StructField(\"City\",StringType(),True),\n",
    "                    StructField(\"Country\",StringType(),True),\n",
    "                    StructField(\"Phone 1\",StringType(),True),\n",
    "                    StructField(\"Phone 2\",StringType(),True),\n",
    "                    StructField(\"Email\",StringType(),True),\n",
    "                    StructField(\"Subscription Date\",DateType(),True),\n",
    "                    StructField(\"Website\",StringType(),True),\n",
    "                    StructField(\"Age\",IntegerType(),True),\n",
    "                    StructField(\"Salary\",IntegerType(),True)\n",
    "                   ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6a675157",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.option(\"header\",True).schema(schema).csv('/home/5AIMLA1/Downloads/customer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "816c24b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-----------+----------+---------+-------+----+-------+-------+-------+-----+-------+---+------+\n",
      "|summary|Index|Customer Id|First Name|Last Name|Company|City|Country|Phone 1|Phone 2|Email|Website|Age|Salary|\n",
      "+-------+-----+-----------+----------+---------+-------+----+-------+-------+-------+-----+-------+---+------+\n",
      "|  count|  100|        100|       100|      100|    100| 100|    100|    100|    100|  100|    100|100|   100|\n",
      "+-------+-----+-----------+----------+---------+-------+----+-------+-------+-------+-----+-------+---+------+\n",
      "only showing top 1 row\n"
     ]
    }
   ],
   "source": [
    "df.describe().show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2abee208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------+----------+---------+---------------+-----------------+--------------+-----------------+--------------------+--------------------+-----------------+--------------------+---+------+\n",
      "|Index|    Customer Id|First Name|Last Name|        Company|             City|       Country|          Phone 1|             Phone 2|               Email|Subscription Date|             Website|Age|Salary|\n",
      "+-----+---------------+----------+---------+---------------+-----------------+--------------+-----------------+--------------------+--------------------+-----------------+--------------------+---+------+\n",
      "|   17|a5DC21AE3a21eaA|  Caroline|    Foley|Winters-Mendoza|West Adriennestad|Western Sahara|936.222.4746x9924|001-469-948-6341x359|holtgwendolyn@wat...|       2021-03-10|http://www.benson...| 26| 35015|\n",
      "|   18|F8Aa9d6DfcBeeF8|      Greg|     Mata|  Valentine LLC|      Lake Leslie|    Mozambique|    (701)087-2415| (195)156-1861x26241|jaredjuarez@carro...|       2022-03-26|http://pitts-cher...| 27| 35016|\n",
      "+-----+---------------+----------+---------+---------------+-----------------+--------------+-----------------+--------------------+--------------------+-----------------+--------------------+---+------+\n",
      "only showing top 2 rows\n"
     ]
    }
   ],
   "source": [
    "filt= df.filter(col('age')> 25)\n",
    "filt.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0a004d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------+----------+---------+--------------------+-----------+-----------+--------------------+--------------------+--------------------+-----------------+--------------------+---+------+\n",
      "|Index|    Customer Id|First Name|Last Name|             Company|       City|    Country|             Phone 1|             Phone 2|               Email|Subscription Date|             Website|Age|Salary|\n",
      "+-----+---------------+----------+---------+--------------------+-----------+-----------+--------------------+--------------------+--------------------+-----------------+--------------------+---+------+\n",
      "|   21|9F9AdB7B8A6f7F2|   Maxwell|     Frye|       Patterson Inc| East Carly|      Malta|        423.262.3059|   202-880-0688x7491|fgibson@drake-web...|       2022-01-12|http://www.robert...| 30| 35019|\n",
      "|   22|FBd0Ded4F02a742|     Kiara|  Houston|Manning, Hester a...|South Alvin|Netherlands|001-274-040-3582x...|+1-528-175-0973x4684|blanchardbob@wall...|       2020-09-15|https://www.reid-...| 31| 35020|\n",
      "+-----+---------------+----------+---------+--------------------+-----------+-----------+--------------------+--------------------+--------------------+-----------------+--------------------+---+------+\n",
      "only showing top 2 rows\n"
     ]
    }
   ],
   "source": [
    "filt2= df.filter(\"Age >= 29\")\n",
    "filt2.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8c80f667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+------+\n",
      "|First Name|Age Group|Salary|\n",
      "+----------+---------+------+\n",
      "|    Sheryl|   Adults| 30000|\n",
      "|   Preston|   Adults| 35000|\n",
      "|       Roy|     Kids| 35001|\n",
      "|     Linda|     Kids| 35002|\n",
      "|    Joanna|     Kids| 35003|\n",
      "|     Aimee|     Kids| 35004|\n",
      "|    Darren|   Adults| 35005|\n",
      "|     Brett|     Kids| 35006|\n",
      "|    Sheryl|   Adults| 35007|\n",
      "|  Michelle|   Adults| 35008|\n",
      "|      Carl|   Adults| 35009|\n",
      "|     Jenna|   Adults| 35010|\n",
      "|    Tracey|   Adults| 35011|\n",
      "|  Kristine|   Adults| 35012|\n",
      "|     Faith|   Adults| 35013|\n",
      "|   Miranda|   Adults| 35014|\n",
      "|  Caroline|   Adults| 35015|\n",
      "|      Greg|   Adults| 35016|\n",
      "|  Clifford|   Adults| 39017|\n",
      "|    Joanna|   Adults| 35018|\n",
      "+----------+---------+------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "df2= df.withColumn(\"Age Group\",when(col('Age')<=17,\"Kids\").otherwise(\"Adults\"))\n",
    "\n",
    "df2.select(\"First Name\",\"Age Group\",\"Salary\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee16f81",
   "metadata": {},
   "source": [
    "### Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cfd55937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 100\n",
      "\n",
      "\n",
      "+----------+-----------+---+---------+\n",
      "|First Name|  Last Name|Age|Age Group|\n",
      "+----------+-----------+---+---------+\n",
      "|   Colleen|     Howard| 32|   Adults|\n",
      "|     Janet| Valenzuela| 33|   Adults|\n",
      "|    Marcus|      Moody| 35|   Adults|\n",
      "|    Dakota|      Poole| 36|   Adults|\n",
      "| Frederick|     Harper| 37|   Adults|\n",
      "|  Stefanie|Fitzpatrick| 38|   Adults|\n",
      "|      Kent|   Bradshaw| 39|   Adults|\n",
      "|      Jack|       Tate| 40|   Adults|\n",
      "|       Tom|   Trujillo| 41|   Adults|\n",
      "|   Gabriel|      Mejia| 42|   Adults|\n",
      "|   Kaitlyn|    Santana| 35|   Adults|\n",
      "|     Faith|       Moon| 46|   Adults|\n",
      "|    Tammie|      Haley| 45|   Adults|\n",
      "|    Jordan|        Gay| 47|   Adults|\n",
      "|     Bruce|    Esparza| 48|   Adults|\n",
      "|    Sherry|      Garza| 49|   Adults|\n",
      "|   Natalie|     Gentry| 50|   Adults|\n",
      "|     Bryan|       Dunn| 51|   Adults|\n",
      "|     Wayne|    Simpson| 52|   Adults|\n",
      "|      Luis|      Greer| 53|   Adults|\n",
      "+----------+-----------+---+---------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "rowCount= df.count()\n",
    "print(f'Number of rows: {rowCount}\\n\\n')\n",
    "\n",
    "df2.filter((col(\"Age\")>=32) &( col(\"Age\")<=66)).select('First Name','Last Name','Age','Age Group').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a23365",
   "metadata": {},
   "source": [
    "### Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "31540943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+\n",
      "|Summary|               Age|           Salary|\n",
      "+-------+------------------+-----------------+\n",
      "|  count|               100|              100|\n",
      "|   mean|              49.0|          57591.3|\n",
      "| stddev|27.390553558524957|63861.05063789477|\n",
      "|    min|                10|             1000|\n",
      "|    max|               107|           435066|\n",
      "+-------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().select('Summary','Age','Salary').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ccc53ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|min_salary|\n",
      "+----------+\n",
      "|      1000|\n",
      "+----------+\n",
      "\n",
      "+-------+\n",
      "|max_age|\n",
      "+-------+\n",
      "|    107|\n",
      "+-------+\n",
      "\n",
      "+------------+\n",
      "|people_count|\n",
      "+------------+\n",
      "|         100|\n",
      "+------------+\n",
      "\n",
      "+-------+----------+\n",
      "|Sum_age|Avg_salary|\n",
      "+-------+----------+\n",
      "|   4900|   57591.3|\n",
      "+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.agg(min(\"salary\").alias(\"min_salary\")).show()\n",
    "df.agg(max(\"age\").alias(\"max_age\")).show()\n",
    "df.agg(count(\"First Name\").alias(\"people_count\")).show()\n",
    "df.agg(sum(\"Age\").alias(\"Sum_age\"), avg(\"Salary\").alias(\"Avg_salary\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa924184",
   "metadata": {},
   "source": [
    "### Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "52068280",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.write.csv('/home/5AIMLA1/Desktop/230962012', header=True,mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0e5057",
   "metadata": {},
   "source": [
    "### q5: Implement wordcount program in PySpark by loading a text file from the local file system.\n",
    "- Dispplay total no of words and compare it with no.of unique words in the file\n",
    "- Find the total no of words that begin with letter 'a'\n",
    "- Determine frequency of each word and save the output in local file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5b851246",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|Quod equidem non ...|\n",
      "+--------------------+\n",
      "only showing top 1 row\n"
     ]
    }
   ],
   "source": [
    "df3=spark.read.text(\"/home/5AIMLA1/Downloads/sample3.txt\")\n",
    "df3.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2686e560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_rows= df3.count()\n",
    "total_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7e61f06e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "split() missing 1 required positional argument: 'pattern'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[104]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m word_col= df3.withColumn(\u001b[33m\"\u001b[39m\u001b[33mWords\u001b[39m\u001b[33m\"\u001b[39m,explode(\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalue\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m,\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33ms+\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myenv/lib/python3.11/site-packages/pyspark/sql/utils.py:282\u001b[39m, in \u001b[36mtry_remote_functions.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    280\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(functions, f.\u001b[34m__name__\u001b[39m)(*args, **kwargs)\n\u001b[32m    281\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m282\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: split() missing 1 required positional argument: 'pattern'"
     ]
    }
   ],
   "source": [
    "word_col= df3.withColumn(\"Words\",explode(split(col(\"value\")),\"\\\\s+\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sparkenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
